---
title: 同步MySQL表结构和数据
date: 2023-03-24 13:17:11
permalink: /pages/461816/
categories:
  - Linux
  - Shell脚本
tags:
  - 
---
```bash
#!/bin/bash

# 数据库备份脚本

# 配置信息
# 数据库地址数组，可以添加多个地址
DB_HOST=("数据库地址1" "数据库地址2" "数据库地址3")
# 数据库用户名数组，与数据库地址一一对应
DB_USERS=("数据库用户1" "数据库用户2" "数据库用户3")
# 数据库密码数组，与数据库地址一一对应
DB_USERS_PASSWORDS=("数据库密码1" "数据库密码2" "数据库密码3")
# 数据库名数组，与数据库地址一一对应
DB_NAMES=("数据库名1" "数据库名2" "数据库名3")
# 存储数据表名的文件路径
TABLES_FILE="./TABLES_FILE.txt"
# 存储导出数据表的路径
EXPORT_PATH="./TABLES_STORAGE_PATH"
# 日志文件路径
LOG_FILE="./process.log"

# 选择数据库
choose_export_db() {
    # 参数 1：提示信息
    local message=$1
    # 数据库地址数组，复制数组防止修改原数组
    local db_names=("${DB_NAMES[@]}") 
    echo "${message}（输入 q 退出脚本）："
    select db in "${db_names[@]}"; do
        case $db in
            "${DB_NAMES[0]}") export_db=0 ; break;;
            "${DB_NAMES[1]}") export_db=1 ; break;;
            "${DB_NAMES[2]}") export_db=2 ; break;;
            "q") echo -e "\033[31m脚本退出\033[0m"; exit;;
            *) echo -e "\033[31m错误：请输入正确的选项\033[0m"; break;;
        esac
    done
}

choose_import_db() {
    # 参数 1：提示信息
    local message=$1
    # 数据库地址数组，复制数组防止修改原数组
    local db_names=("${DB_NAMES[@]}") 
    echo "${message}（输入 q 退出脚本）："
    select db in "${db_names[@]}"; do
        case $db in
            "${DB_NAMES[0]}") import_db=0 ; break;;
            "${DB_NAMES[1]}") import_db=1 ; break;;
            "${DB_NAMES[2]}") import_db=2 ; break;;
            "q") echo -e "\033[31m脚本退出\033[0m"; exit;;
            *) echo -e "\033[31m错误：请输入正确的选项\033[0m"; break;;
        esac
    done
}

# 导出数据表并保存
export_table() {
    # 参数 1：数据库索引号；参数 2：数据表名

    # -u ：指定备份时使用的用户名
    #-p ：指定备份时使用的密码
    # -h ：指定备份时连接的 MySQL 主机名或 IP 地址
    # --skip-comments ：备份时跳过注释
    # --compact ：以紧凑格式进行备份，可以减小备份文件的大小
    # --add-locks ：备份时加锁，保证备份数据的完整性，避免备份时数据的改变
    # --set-gtid-purged=OFF：不启用 GTID 模式备份
    # --column-statistics=0：关闭列统计
    # --single-transaction：在备份之前，启动一个事务，保证整个备份是一个事务，保证数据的一致性
    # --skip-triggers：跳过备份触发器

    local db=$1
    local table=$2
    # 导出数据表，成功则返回0，失败则返回1
    if mysqldump -u "${DB_USERS[$db]}" -p"${DB_USERS_PASSWORDS[$db]}" -h "${DB_HOST[$db]}" \
    --skip-comments --compact --add-locks --set-gtid-purged=OFF \
    --column-statistics=0 --single-transaction --skip-triggers \
    "${DB_NAMES[$db]}" "$table" > "${EXPORT_PATH}/${table}.sql"; then
        return 0 # 导出成功
    else
        return 1 # 导出失败
    fi
}

# 导入数据表并清除临时文件
import_table() {
    # 参数 1：数据库索引号；参数 2：数据表名

    # --skip-comments 表示在导入数据时跳过 SQL 文件中的注释。
    # --max_allowed_packet 指定最大允许的数据包大小，该参数可以防止因为一次传输的包太大而导致服务器崩溃。
    # --local_infile 允许从本地文件系统读取数据。

    local db=$1
    local table=$2
    # 导入数据表，成功则返回0，失败则返回1
    if mysql -u "${DB_USERS[$db]}" -p"${DB_USERS_PASSWORDS[$db]}" -h "${DB_HOST[$db]}" \
    --max_allowed_packet=200M \
    "${DB_NAMES[$db]}" < "${EXPORT_PATH}/${table}.sql"; then
        rm -rf "${EXPORT_PATH}/${table}.sql" # 删除临时存储的数据表文件
        return 0 # 导入成功
    else
        return 1 # 导入失败
    fi
}

# 处理数据表
process_table() {
    # 参数 1：数据表名
    local table=$1
    # 如果导出和导入数据表都成功，则提示数据表处理完成，并将处理完成的数据表名记录到日志文件中；否则提示处理失败，并将处理失败的数据表名记录到日志文件中
    if export_table "${export_db}" "${table}" && import_table "${import_db}" "${table}"; then
        echo -e "\033[32m数据表：${table} 处理完成\033[0m" # 处理成功提示信息
        echo "$(date '+%Y-%m-%d %H:%M:%S') ${table} 处理完成" >> "${LOG_FILE}" # 将处理完成的数据表名记录到日志文件中
        return 0 # 处理成功
    else
        echo -e "\033[31m数据表：${table} 处理失败\033[0m" # 处理失败提示信息
        echo "$(date '+%Y-%m-%d %H:%M:%S') ${table} 处理失败" >> "${LOG_FILE}" # 将处理失败的数据表名记录到日志文件中
        return 1 # 处理失败
    fi
}

# 检查文件和路径是否存在
if [ ! -f "${TABLES_FILE}" ]; then
    echo -e "\033[31m错误：数据表名文件不存在\033[0m"
    exit
fi
if [ ! -d "${EXPORT_PATH}" ]; then
    mkdir "${EXPORT_PATH}"
fi

# 判断导入和导出的数据库是否相同
choose_export_db "请选择导出的数据库"
choose_import_db "请选择导入的数据库"

# 处理数据表
while IFS= read -r table ; do # 从文件中循环读取数据表名
    process_table "${table}" # 处理数据表
done < "${TABLES_FILE}" # 从文件中读取数据表名

# 输出结束信息
echo -e  "\033[36m==============================\n=============完成=============\n==============================\033[0m" # 输出处理完成信息
echo "$(date '+%Y-%m-%d %H:%M:%S') 脚本运行成功" >> "${LOG_FILE}" # 将运行成功的记录写入日志文件中
```

